{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecast - ARIMA\n",
    "\n",
    "### Kumar Rahul\n",
    "\n",
    "Forecasting the demand of services or products leads to better management of short term or long term planning. In this case, we are looking at the warranty related issues reported, on a particular brand of two-wheeler. The data is a monthly roll-up of approximately half a million issues reported by the customers over a four year period. \n",
    "We will be using Claim forecasting data in this exercise. Refer the **Exhibit 1** to understand the feature list. Use the data and answer the below questions.\n",
    "\n",
    "1.\tLoad the time series dataset in Jupyter Notebook using pandas.\n",
    "2.\tTest stationarity of data using augmented dickey fuller test.\n",
    "3.\tUse data differencing as a strategy to make the data stationary.\n",
    "4.\tPlot the ACF and PACF plot. How will you inspect the plot to arrive at the p-lags and q-lags?\n",
    "5.\tSplit the data into training set and test set. Use walk forward validation strategy for model building and evaluation.\n",
    "6.\tGiven recent claim, what is the expected claim for the next time period? Build a model with statsmodel.api to forecast the amount claimed in next time step.\n",
    "7.\tCheck for validity of model using ACF and PACF plot for error term. What do you observe in these plots?\n",
    "8.\t How do you interpret the model outcome? Report the model performance on the walk forward validation set.\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "|Sl. No.|Name of Variable|Variable Description|\n",
    "|----------|------------|---------------|\n",
    "|1\t|date\t|Date of Claim|\n",
    "|2\t|rate\t|Amount claimed|\n",
    "|3\t|item\t|Number of claims|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_raw_df = pd.read_csv('./data/data_monthly.csv', sep=',', header=0, \n",
    "                             low_memory=False, infer_datetime_format=True, \n",
    "                             index_col=['date'], \n",
    "                             parse_dates= ['date'],dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_raw_df.sort_index(inplace=True)\n",
    "monthly_raw_df.columns = monthly_raw_df.columns.str.lower().str.replace('.', '_')\n",
    "monthly_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the first day and last day of CGM monitoring being trucated as it has not been captured for the full cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_filter_df = monthly_raw_df.filter(['rate'], axis =1)\n",
    "monthly_filter_df['rate'] = monthly_filter_df['rate'].map(lambda x:str(x).replace(',', '')).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_filter_df = monthly_filter_df[(monthly_filter_df.index >='2014-03-01') & \n",
    "                                      (monthly_filter_df.index <= '2017-05-31')]\n",
    "\n",
    "monthly_filter_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Framing\n",
    "\n",
    "\n",
    "We will use the data to explore a very specific question; that is:\n",
    "\n",
    "**Given recent claim, what is the expected claim for the next time period?**\n",
    "\n",
    "Plot of the original data is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.figure(figsize = (18, 5))\n",
    "pyplot.plot(monthly_filter_df, 'b-')\n",
    "pyplot.title('Monthly amount claimed over a 3 year period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity\n",
    "\n",
    "We can assume the series to be stationary if it has constant statistical properties over time, i.e. the following:\n",
    "\n",
    "> 1. constant mean - The mean of the series should not be a function of time rather should be a constant. \n",
    "2. constant variance - The variance of the series should not a be a function of time. This property is known as homoscedasticity. \n",
    "3. an autocovariance that does not depend on time - The covariance of the i th term and the (i + m) th term should not be a function of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, we can check stationarity using the following:\n",
    "\n",
    "> Dickey-Fuller Test: This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the TS is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the ‘Test Statistic’ is less than the ‘Critical Value’, we can reject the null hypothesis and say that the series is stationary.\n",
    "\n",
    "\n",
    "The below function which takes a timeseries data as input and perform the Dickey-Fuller test to check stationarity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def df_test(data):\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(data.iloc[:,0].values, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test(monthly_filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-vlaue is not greater than the 5% or 10% cofidence level, suggests that the timeseries is stationary. As the series is statioanry, differencing may not be required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make time series stationary\n",
    "\n",
    "There are 2 major reasons behind non-stationarity of a time series data:\n",
    "\n",
    "> * Trend – varying mean over time. In this case we can see that on average, the claim is varying  over time.\n",
    "* Seasonality – variations at specific time-frames. In this case, claim might be high during some time period owing to climatic conditions leading to wear and tear.\n",
    "\n",
    "\n",
    "The underlying principle is to estimate the trend and seasonality in the series and remove those from the series to get a stationary series. Then statistical forecasting techniques can be implemented on the filtered series. The final step would be to convert the forecasted values into the original scale by applying trend and seasonality constraints back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Eliminate Trend and Seasonality\n",
    "\n",
    "The simple trend reduction techniques discussed before don’t work in all cases, particularly the ones with high seasonality. Two widely used techniques of removing trend and seasonality:\n",
    "\n",
    "> * Differencing – taking the differece with a particular time lag\n",
    "* Decomposition – modeling both trend and seasonality and removing them from the model. We will not be discussing this technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differencing\n",
    "One of the most common methods of dealing with both trend and seasonality is differencing. In this technique, the difference of the observation at a particular instant with that at the previous instant is taken. This mostly works well in improving stationarity. First order differencing can be done in Pandas as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "monthly_filter_log_df = np.log(monthly_filter_df)\n",
    "monthly_filter_log_diff_df = monthly_filter_log_df - monthly_filter_log_df.shift(1)\n",
    "\n",
    "pyplot.figure(figsize = (18, 5))\n",
    "diff = pyplot.plot(monthly_filter_log_diff_df, color='red',label='Difference')\n",
    "monthly_filter_log_diff_df.dropna(inplace=True)\n",
    "monthly_filter_log_diff_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to have reduced trend considerably. Same is evident in the plot and test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test(monthly_filter_log_diff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try second order and third order differencing to further remove the variation. Since for this dataset, the time series is stationary we can set d = 0 and will find the value of p and q using ACF and PACF plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation Analysis\n",
    "\n",
    "We can assume the distribution of each variable fits a Gaussian (bell curve) distribution. If this is the case, we can use the Pearson’s correlation coefficient to summarize the correlation between the variables.\n",
    "\n",
    "The Pearson’s correlation coefficient is a number between -1 and 1 that describes a negative or positive correlation respectively. A value of zero indicates no correlation.\n",
    "\n",
    "We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.\n",
    "\n",
    "A plot of the autocorrelation of a time series by lag is called the AutoCorrelation Function, or the acronym ACF. This plot is sometimes called a correlogram, or an autocorrelation plot.\n",
    "\n",
    "A partial autocorrelation function or PACF is a summary of the relationship between an observation in a time series with observations at prior time steps with the relationships of intervening observations removed.\n",
    "\n",
    "The autocorrelation for an observation and an observation at a prior time step is comprised of both the direct correlation and indirect correlations. These indirect correlations are a linear function of the correlation of the observation, with observations at intervening time steps.\n",
    "\n",
    "It is these indirect correlations that the partial autocorrelation function seeks to remove. This is the intuition for the partial autocorrelation.\n",
    "\n",
    "We can calculate autocorrelation and partial autocorrelation plots using the plot_acf() and plot_pacf() statsmodels functions respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACF and PACF plot for the monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plots\n",
    "pyplot.figure(figsize = (25, 15))\n",
    "lags = 20\n",
    "# acf\n",
    "axis = pyplot.subplot(2, 1, 1)\n",
    "plot_acf(monthly_filter_df, ax=axis, lags=lags)\n",
    "# pacf\n",
    "axis = pyplot.subplot(2,1,2)\n",
    "plot_pacf(monthly_filter_df, ax=axis, lags=lags)\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets\n",
    "We will use the first three years of data for training predictive models and the final year for evaluating models.\n",
    "\n",
    "The function split_filter_df() below splits the monthly data into train and test sets and organizes each into standard weeks.\n",
    "\n",
    "Specific row offsets are used to split the data using knowledge of the filter_df. The split filter_dfs are then organized into  data using the NumPy split() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_filter_df(data):\n",
    "    split_point = len(data) - 10\n",
    "    train, test = data[0:split_point], data[split_point:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new file\n",
    "train, test = split_filter_df(monthly_filter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate train data\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate test data\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "Both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) can be used. Unlike MAE, RMSE is more punishing of forecast errors.\n",
    "\n",
    "The function evaluate_forecasts_rmse() and evaluate_forecasts_mape() is being used for evaluating model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more  forecasts against expected values\n",
    "def evaluate_forecasts_rmse(actual):\n",
    "    score_rmse = 0\n",
    "    se = 0\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[0]):\n",
    "        # calculate mse\n",
    "        se += (actual.iloc[i,0] - actual.iloc[i,1])**2\n",
    "        # calculate rmse\n",
    "    score_rmse = sqrt(se/actual.shape[0])\n",
    "    return score_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more  forecasts against expected values\n",
    "def evaluate_forecasts_mape(actual):\n",
    "    score_mape = 0\n",
    "    ape = 0\n",
    "    for i in range(actual.shape[0]):\n",
    "        # calculate mse\n",
    "        ape += np.abs(((actual.iloc[i,0] - actual.iloc[i,1])/actual.iloc[i,0]))\n",
    "        # calculate mape\n",
    "    score_mape = (ape)/actual.shape[0]\n",
    "    return actual, score_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation\n",
    "Models will be evaluated using a scheme called walk-forward validation.\n",
    "\n",
    "This is where a model is required to make a one month prediction, then the actual data for that month is made available to the model so that it can be used as the basis for making a prediction on the subsequent month. This is both realistic for how the model may be used in practice and beneficial to the models, allowing them to make use of the best available data.\n",
    "\n",
    "A walk-forward validation, or rolling forecast, method is used as follows:\n",
    "\n",
    "> * Each time step in the test dataset is iterated.\n",
    "* Within each iteration, a new ARIMA model is trained on all available historical data.\n",
    "* The model is used to make a prediction for the next time step.\n",
    "* The prediction is stored and the “real” observation is retrieved from the test set and added to the history for use in the next iteration.\n",
    "* The performance of the model is summarized at the end by calculating the root mean squared error (RMSE) of all predictions made compared to expected values in the test dataset.\n",
    "\n",
    "\n",
    "The name of a function is provided for the model as the argument “model_func“. This function is responsible for defining the model, fitting the model on the training data, and making a one-week forecast.\n",
    "\n",
    "The forecasts made by the model are then evaluated against the test dataset using the previously defined evaluate_forecasts() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test, order):\n",
    "    # history is a list of  data\n",
    "    history = train.filter(['rate'], axis = 1)\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = model_func(history, order)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)      \n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history = history.append(test.iloc[[i]])\n",
    "    predictions = array(predictions)\n",
    "    test['prediction'] = predictions\n",
    "    # evaluate predictions days for each week\n",
    "    actual, score_mape = evaluate_forecasts_mape(test[:])\n",
    "    score_rmse = evaluate_forecasts_rmse(test[:])\n",
    "    return actual, score_mape, score_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop an Autoregression Model\n",
    "We can develop an autoregression model for univariate series of monthly claims.\n",
    "\n",
    "The Statsmodels library provides multiple ways of developing an AR model, such as using the AR, ARMA, ARIMA, and SARIMAX classes.\n",
    "\n",
    "We will use the ARIMA implementation as it allows for easy expandability into differencing and moving average.\n",
    "\n",
    "Note: To make holts winter model, use:\n",
    "\n",
    "> * `import statsmodels.tsa.holtwinters as hw`\n",
    "* `model = hw.ExponentialSmoothing()`\n",
    "\n",
    "Help on the model - hw.ExponentialSmoothing.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima forecast\n",
    "def arima_forecast(history, pdq):\n",
    "    # define the model\n",
    "    model = ARIMA(history, order=pdq)\n",
    "    # fit the model\n",
    "    model_fit = model.fit(trend = 'nc',disp=0)\n",
    "    # make forecast\n",
    "    yhat = model_fit.forecast(steps=1)[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_column(test):\n",
    "    for n in test.columns:\n",
    "        if n =='prediction':\n",
    "            test.drop('prediction', axis = 1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define the names and functions for the models we wish to evaluate\n",
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "\n",
    "import itertools\n",
    "p_values = [0,1,2]\n",
    "d_values  = [0, 1]\n",
    "q_values = [0, 1, 2]\n",
    "\n",
    "pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# evaluate each model\n",
    "for name, func in models.items():\n",
    "    best_mape,best_rmse, best_cfg = float(\"inf\"), float(\"inf\"), None\n",
    "    for pdq in pdq:\n",
    "        order = pdq\n",
    "        del_column(test)\n",
    "        try:\n",
    "            actual, score_mape, score_rmse= evaluate_model(func, train, test, pdq)\n",
    "            if score_rmse < best_rmse:\n",
    "                best_rmse, best_mape, best_cfg = score_rmse, score_mape, order\n",
    "            print('ARIMA%s MAPE=%.5f RMSE=%.4f' % (order,score_mape,score_rmse))\n",
    "        except:\n",
    "            continue\n",
    "    print('Best ARIMA%s MAPE=%.5f RMSE=%.5f' % (best_cfg,best_mape, best_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "\n",
    "# evaluate each model\n",
    "for name, func in models.items():\n",
    "    pdq = (1,0,0)\n",
    "    del_column(test)\n",
    "    actual, score_mape, score_rmse= evaluate_model(func, train, test, pdq)\n",
    "    print('ARIMA%s MAPE=%.5f RMSE=%.4f' % (pdq,score_mape,score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coversion is needed only if the train data was log transformed. If not transformed then we can directly compute the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual['converted_rate'] = np.exp(actual.rate)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual['converted_forecast'] = np.exp(actual.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ape = 0\n",
    "se=0\n",
    "for i in range(actual.shape[0]):\n",
    "        # calculate mse\n",
    "        ape += np.abs(((np.exp(actual.iloc[i,0]) - np.exp(actual.iloc[i,1]))/np.exp(actual.iloc[i,0])))\n",
    "        # calculate mape\n",
    "        se += (np.exp(actual.iloc[i,0]) - np.exp(actual.iloc[i,1]))**2\n",
    "        # calculate rmse\n",
    "                       \n",
    "score_mape = (ape)/actual.shape[0]\n",
    "score_rmse = sqrt(se/actual.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual['error']= actual.rate-actual.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "pyplot.figure(figsize = (25, 15))\n",
    "lags = 9\n",
    "# acf\n",
    "axis = pyplot.subplot(2, 1, 1)\n",
    "plot_acf(actual.error, ax=axis, lags=lags)\n",
    "# pacf\n",
    "axis = pyplot.subplot(2,1,2)\n",
    "plot_pacf(actual.error, ax=axis, lags=lags)\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual.to_csv('monthly_forecast.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
